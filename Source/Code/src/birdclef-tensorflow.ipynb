{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\nimport tensorflow.keras as tfk\nfrom tensorflow.keras.layers import Dense, Flatten, Conv1D, Embedding, Normalization, Conv1DTranspose,InputLayer\nimport tensorflow.keras.layers as tfkl\nfrom tensorflow.keras import Model\nimport math\nimport time\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport librosa\nimport json\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow_io as tfio\nimport random\nimport tensorflow as tf\nfrom pathlib import Path\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-16T03:51:17.209027Z","iopub.execute_input":"2022-05-16T03:51:17.209453Z","iopub.status.idle":"2022-05-16T03:51:27.184402Z","shell.execute_reply.started":"2022-05-16T03:51:17.209319Z","shell.execute_reply":"2022-05-16T03:51:27.183619Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('../input/birdclef-2022/scored_birds.json','r') as sb:\n  s_b = json.load(sb)\nfile_path = '../input/birdclef-2022'\ntrain_df = pd.read_csv('../input/birdclef-2022/train_metadata.csv')\ntrain_df = train_df[train_df['primary_label'].isin(s_b)]\nbird_label = train_df[\"primary_label\"].unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T03:51:27.186498Z","iopub.execute_input":"2022-05-16T03:51:27.187076Z","iopub.status.idle":"2022-05-16T03:51:27.307096Z","shell.execute_reply.started":"2022-05-16T03:51:27.187031Z","shell.execute_reply":"2022-05-16T03:51:27.306257Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv('../input/birdclef-2022/sample_submission.csv')\ntest_df = pd.read_csv('../input/birdclef-2022/test.csv')\nif test_df.shape[0] != submission_df.shape[0]:\n    raise ValueError('test submission row number didnt match')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T03:51:27.308704Z","iopub.execute_input":"2022-05-16T03:51:27.308949Z","iopub.status.idle":"2022-05-16T03:51:27.322736Z","shell.execute_reply.started":"2022-05-16T03:51:27.308915Z","shell.execute_reply":"2022-05-16T03:51:27.322062Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/birdclef-2022/train_audio'\n\ndef preprocessing(df, path,bird_label):\n  le = 160000\n  step = int((le/2))\n  sample_rate = 32000\n  train = []\n  for label in tqdm(bird_label):\n    files = librosa.util.find_files(os.path.join(path, label))\n    for f in tqdm(files):\n      yi = np.where(bird_label == label)\n      # load audio\\\n      #print(\"1:\",type(yi),type(yi.shape),yi[:10])\n      y, sr = librosa.load(f,sr=sample_rate)\n      #print(y)\n      y = ((y-np.amin(y))*2)/(np.amax(y) - np.amin(y)) - 1\n      #print(\"2:\",type(y),y.shape,y[:10])\n      \n      org_len = len(y)\n      intervals = librosa.effects.split(y, top_db= 15, ref= np.max)\n      intervals = intervals.tolist()\n      #print(\"3-1:\",type(y),y.shape,y[:10])\n\n      y = (y.flatten()).tolist()\n      #print(\"3:\",type(y),y[:10])\n      \n      nonsilent_y = []\n\n      for p,q in intervals :\n       nonsilent_y = nonsilent_y + y[p:q+1] \n      #print(\"4:\",type(nonsilent_y),nonsilent_y[:10])\n      y = np.array(nonsilent_y).astype('float32')\n      if len(y) < le:\n        while len(y) < le:\n          y = np.concatenate((y, y))\n        y = y[:le]\n      #print(\"5:\",type(y),y.shape,y[:10])\n      \n      # A 1024-point STFT with frames of 5 s and 50% overlap.\n      stfts = tf.signal.stft(y, frame_length=le, frame_step=step,\n                       fft_length=4096)\n      #print(\"6:stfts\",type(stfts),stfts[:10])\n      spectrograms = tf.abs(stfts)\n\n      # Warp the linear scale spectrograms into the mel-scale.\n      num_spectrogram_bins = stfts.shape[-1]\n      #print(\"7: num_spectrograms\",type(num_spectrogram_bins),num_spectrogram_bins)\n      lower_edge_hertz, upper_edge_hertz, num_mel_bins = 1000.0, 8000.0, 4096\n        \n      linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n        num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n        upper_edge_hertz)\n      #print(\"8: linear_to_mel_spectorgrams_matrix\",type(linear_to_mel_weight_matrix),linear_to_mel_weight_matrix[:10])\n     \n        \n      mel_spectrograms = tf.tensordot(\n        spectrograms, linear_to_mel_weight_matrix, 1)\n      #print(\"9: mel_spectrograms\",type(mel_spectrograms),mel_spectrograms[:10])\n        \n      mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n        linear_to_mel_weight_matrix.shape[-1:]))\n      #print(\"continuous to mel spectrogema the shsape of the mel is \",mel_spectrograms.shape)\n        \n      # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n      log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n      #print(\"9: log_mel_spectrograms:\",type(log_mel_spectrograms),log_mel_spectrograms[:10])\n    \n      \n      mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n        log_mel_spectrograms)\n      print(\"final\",type(mfccs),mfccs.shape,mfccs[:10])\n\n      for mfc in mfccs:\n        train.append((mfc, yi))\n  return train","metadata":{"execution":{"iopub.status.busy":"2022-05-16T03:51:27.324274Z","iopub.execute_input":"2022-05-16T03:51:27.324792Z","iopub.status.idle":"2022-05-16T03:51:27.339802Z","shell.execute_reply.started":"2022-05-16T03:51:27.324752Z","shell.execute_reply":"2022-05-16T03:51:27.338946Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data = preprocessing(train_df, train_path, bird_label)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T03:51:27.342735Z","iopub.execute_input":"2022-05-16T03:51:27.343009Z","iopub.status.idle":"2022-05-16T04:07:12.522015Z","shell.execute_reply.started":"2022-05-16T03:51:27.342970Z","shell.execute_reply":"2022-05-16T04:07:12.519460Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class TensorflowDataGenerator():\n    'Characterizes a dataset for Tensorflow'\n    def __init__(self, mel_list, batch_size):\n      self.mel_list = mel_list\n      self.batch_size = batch_size\n      self.index_helper = 0\n      self.le = len(mel_list)\n    def __len__(self):\n        return math.ceil(self.le/ self.batch_size)\n\n    def __getitem__(self, index):\n      if self.index_helper >= self.le:\n        raise IndexError\n      x, y = [], []\n      for b in range(self.batch_size):\n        if self.index_helper < self.le:\n          #print(\"shape of original mel_list\",mel)\n          x.append(tf.expand_dims(self.mel_list[self.index_helper][0],0))\n          y.append(tf.squeeze(self.mel_list[self.index_helper][1]))\n          self.index_helper += 1\n          \n      return np.array(x).astype('float32'), np.array(y).astype('float32')\n\n    def reset(self):\n      self.index_helper = 0\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:07:12.523484Z","iopub.execute_input":"2022-05-16T04:07:12.523758Z","iopub.status.idle":"2022-05-16T04:07:12.533400Z","shell.execute_reply.started":"2022-05-16T04:07:12.523721Z","shell.execute_reply":"2022-05-16T04:07:12.532263Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"random.seed(2022)\nrandom.shuffle(train_data)  # shuffle it randomly\n\ntraining_data = train_data[:int(0.9*len(train_data))]\nval_data = train_data[int(0.9*len(train_data)):]\n\nbatch_size = 32\n\n\ntrain_set = TensorflowDataGenerator(training_data,batch_size)\n\n\nval_set = TensorflowDataGenerator(val_data,batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:07:12.534627Z","iopub.execute_input":"2022-05-16T04:07:12.535260Z","iopub.status.idle":"2022-05-16T04:07:12.555802Z","shell.execute_reply.started":"2022-05-16T04:07:12.535221Z","shell.execute_reply":"2022-05-16T04:07:12.554751Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Dense, Dropout\nfrom tensorflow.keras.layers import AvgPool1D, GlobalAveragePooling1D, MaxPool1D, Conv1DTranspose\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import ReLU, concatenate\nimport tensorflow.keras.backend as K\n# Creating Densenet121\ntf.random.set_seed(2022)\ndef densenet(input_shape, n_classes, filters = 32):   \n    #batch norm + relu + conv\n    def bn_rl_conv(x,filters,kernel=1,strides=1):\n        x = BatchNormalization()(x)\n        x = ReLU()(x)\n        x = Conv1D(filters, kernel, strides=strides,padding = 'same')(x)\n        x = Dropout(0.1)(x)\n        return x\n    \n    def dense_block(x, repetition):\n        \n        for _ in range(repetition):\n            y = bn_rl_conv(x, 4*filters)\n            y = bn_rl_conv(y, filters, 3)\n            x = concatenate([y,x])\n        return x\n        \n    def transition_layer(x):\n        \n        x = bn_rl_conv(x, K.int_shape(x)[-1] //2 )\n        x = AvgPool1D(2, strides = 2, padding = 'same')(x)\n        return x\n    \n    input = Input (input_shape)\n    x = Conv1D(64, 3, strides=1, padding='causal', dilation_rate = 2, activation = 'relu')(input)\n    x = BatchNormalization()(x)\n    x = Conv1D(64, 3, strides=1, padding='causal', dilation_rate = 4, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(64, 3, strides=1, padding='causal', dilation_rate = 8, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(64, 7, strides = 2, padding = 'same')(x)\n    x = Conv1DTranspose(32, 3,strides=1, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1DTranspose(64, 3,strides=1, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1DTranspose(128, 3,strides=1, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool1D(3, strides = 2, padding = 'same')(x)\n    \n    for repetition in [6,12,32,32]:\n        \n        d = dense_block(x, repetition)\n        x = transition_layer(d)\n    x = GlobalAveragePooling1D()(d)\n    x = Dense(2048 , activation = 'relu',kernel_regularizer=tf.keras.regularizers.L1(0.01),\n    activity_regularizer=tf.keras.regularizers.L2(0.01))(x)\n    x = Dropout(0.25)(x)\n    output = Dense(n_classes, activation = 'softmax')(x)\n    model = Model(input, output)\n    return model\ninput_shape = (1, 4096)\nn_classes = 21\nmodel = densenet(input_shape,n_classes)\n# [6,12,32,32]:","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:07:12.557030Z","iopub.execute_input":"2022-05-16T04:07:12.557278Z","iopub.status.idle":"2022-05-16T04:07:17.090428Z","shell.execute_reply.started":"2022-05-16T04:07:12.557244Z","shell.execute_reply":"2022-05-16T04:07:17.089692Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# learning_rate=1e-4 Adadelta\noptimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\nepoches = 10\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\ntrain_acc = tf.keras.metrics.Mean()\ntrain_loss = tf.keras.metrics.Mean()\nval_acc = tf.keras.metrics.Mean()\nval_loss = tf.keras.metrics.Mean()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:07:17.092036Z","iopub.execute_input":"2022-05-16T04:07:17.092283Z","iopub.status.idle":"2022-05-16T04:07:17.115203Z","shell.execute_reply.started":"2022-05-16T04:07:17.092250Z","shell.execute_reply":"2022-05-16T04:07:17.114570Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(x_batch, y_batch):\n  with tf.GradientTape() as tape:\n    logits = model(x_batch, training=True)\n    loss_value = loss_fn(y_batch, logits)\n    grads = tape.gradient(loss_value, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n    acc_value = tf.math.equal(y_batch, tf.cast(tf.math.argmax(logits, 1),dtype=tf.float32))\n    train_acc.update_state(acc_value)\n    train_loss.update_state(loss_value)\n    \ndef val_step(x_batch_val, y_batch_val):\n\n  val_logits = model(x_batch_val, training=False)\n  loss_value = loss_fn(y_batch_val,val_logits) # check input and ground truth shape \n\n  acc_value = tf.math.equal(y_batch_val, tf.cast(tf.math.argmax(val_logits, 1),dtype=tf.float32))\n  val_acc.update_state(acc_value)\n  val_loss.update_state(loss_value)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:07:17.117322Z","iopub.execute_input":"2022-05-16T04:07:17.117834Z","iopub.status.idle":"2022-05-16T04:07:17.125888Z","shell.execute_reply.started":"2022-05-16T04:07:17.117796Z","shell.execute_reply":"2022-05-16T04:07:17.125141Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epoches):\n  if epoch == 2:\n    optimizer.lr.assign(1e-6)\n  elif epoch == 3:\n    optimizer.lr.assign(1e-5)\n  elif epoch == 5:\n    optimizer.lr.assign(1e-6)\n  start_time = time.time()\n  train_set.reset()\n  val_set.reset()\n  for x_batch, y_batch in tqdm(train_set):\n    train_step(x_batch, y_batch)\n    \n  for x_batch_val, y_batch_val in tqdm(val_set):\n    val_step(x_batch_val, y_batch_val)\n  end_time = time.time()\n  print(f'Epoch: {epoch} \\tTraining Loss: {train_loss.result()} \\tValidation Loss: {val_loss.result()} \\tTraining Accuracy: {train_acc.result()} \\tValidation Accuracy: {val_acc.result()} \\tTime taken: {end_time - start_time}')\n\n    \n  train_acc.reset_states()\n  train_loss.reset_states()\n  val_acc.reset_states()\n  val_loss.reset_states()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:07:17.127213Z","iopub.execute_input":"2022-05-16T04:07:17.127488Z","iopub.status.idle":"2022-05-16T04:15:45.313621Z","shell.execute_reply.started":"2022-05-16T04:07:17.127452Z","shell.execute_reply":"2022-05-16T04:15:45.312837Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef test_step(x_batch_val):\n  val_logits = model(x_batch_val, training=False)\n  return tf.math.argmax(val_logits,1)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:15:45.315131Z","iopub.execute_input":"2022-05-16T04:15:45.315762Z","iopub.status.idle":"2022-05-16T04:15:45.321673Z","shell.execute_reply.started":"2022-05-16T04:15:45.315720Z","shell.execute_reply":"2022-05-16T04:15:45.320819Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"test_path = '../input/birdclef-2022/test_soundscapes/'\ntest_files = os.listdir(test_path)\ndef preprocessing_test_dat(test_path, files):\n  le = 160000\n  step = int((le/2))\n  sample_rate = 32000\n  test = []\n  for file in tqdm(files):\n    y, sr = librosa.load(test_path + file, sr=sample_rate)\n    # y = y[:le + 1]\n    for segment in range(0, len(y), sample_rate*5):\n        row_id = file[:-4] + '_' + str(int((segment + (sample_rate * 5)) / (sample_rate)))\n        if segment+le > len(y):\n            yi = y[segment:]\n            while len(yi) < le:\n              yi = np.concatenate((yi, yi))\n            yi = yi[:le]\n        else:\n            yi = y[segment:segment+le]\n            \n        stfts = tf.signal.stft(yi, frame_length=le, frame_step=le,\n                       fft_length=4096)\n        spectrograms = tf.abs(stfts)\n\n        # Warp the linear scale spectrograms into the mel-scale.\n        num_spectrogram_bins = stfts.shape[-1]\n        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 1000.0, 8000.0, 4096\n\n        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n        num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n        upper_edge_hertz)\n      \n        mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n        mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n          linear_to_mel_weight_matrix.shape[-1:]))\n\n        # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n  \n        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)\n        test.append((row_id, mfccs))\n  return test","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:15:45.323087Z","iopub.execute_input":"2022-05-16T04:15:45.323499Z","iopub.status.idle":"2022-05-16T04:15:45.346816Z","shell.execute_reply.started":"2022-05-16T04:15:45.323437Z","shell.execute_reply":"2022-05-16T04:15:45.345804Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class TensorflowDataGenerator_test():\n    'Characterizes a dataset for Tensorflow'\n    def __init__(self, mel_list, batch_size):\n      self.mel_list = mel_list\n      self.batch_size = batch_size\n      self.index_helper = 0\n      self.le = len(mel_list)\n    def __len__(self):\n        return math.ceil(self.le/ self.batch_size)\n\n    def __getitem__(self, index):\n      if self.index_helper >= self.le:\n        raise IndexError\n      x, y = [], []\n      for b in range(self.batch_size):\n        if self.index_helper < self.le:\n          x.append(self.mel_list[self.index_helper][0])\n          y.append(self.mel_list[self.index_helper][1])\n          self.index_helper += 1\n      return x, np.array(y).astype('float32')\n\n    def reset(self):\n      self.index_helper = 0\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:15:45.351496Z","iopub.execute_input":"2022-05-16T04:15:45.352142Z","iopub.status.idle":"2022-05-16T04:15:45.361703Z","shell.execute_reply.started":"2022-05-16T04:15:45.352109Z","shell.execute_reply":"2022-05-16T04:15:45.360848Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n\n\n\n\n\n\n\ntest_dat = preprocessing_test_dat(test_path, test_files)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:15:45.362833Z","iopub.execute_input":"2022-05-16T04:15:45.363052Z","iopub.status.idle":"2022-05-16T04:15:45.660614Z","shell.execute_reply.started":"2022-05-16T04:15:45.363022Z","shell.execute_reply":"2022-05-16T04:15:45.659336Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\ntest_set = TensorflowDataGenerator_test(test_dat,batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:15:45.661990Z","iopub.execute_input":"2022-05-16T04:15:45.662244Z","iopub.status.idle":"2022-05-16T04:15:45.666934Z","shell.execute_reply.started":"2022-05-16T04:15:45.662209Z","shell.execute_reply":"2022-05-16T04:15:45.666051Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"predictions = []\ntest_set.reset()\nfor x_batch, y_batch in tqdm(test_set):\n    preds = test_step(y_batch)\n    for idx, pred in enumerate(preds):\n        split_code = x_batch[idx].split('_')\n        for bird in bird_label:\n            row_id = split_code[0] +'_'+ split_code[1]+'_' + bird+'_'+split_code[2]\n            predictions.append([row_id, True if bird == bird_label[pred] else False])","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:15:45.668424Z","iopub.execute_input":"2022-05-16T04:15:45.668971Z","iopub.status.idle":"2022-05-16T04:15:51.439905Z","shell.execute_reply.started":"2022-05-16T04:15:45.668933Z","shell.execute_reply":"2022-05-16T04:15:51.439212Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame(predictions,columns=['row_id', 'target'])\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:15:51.441383Z","iopub.execute_input":"2022-05-16T04:15:51.441873Z","iopub.status.idle":"2022-05-16T04:15:51.459749Z","shell.execute_reply.started":"2022-05-16T04:15:51.441834Z","shell.execute_reply":"2022-05-16T04:15:51.459052Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:15:51.461139Z","iopub.execute_input":"2022-05-16T04:15:51.461408Z","iopub.status.idle":"2022-05-16T04:15:51.469626Z","shell.execute_reply.started":"2022-05-16T04:15:51.461363Z","shell.execute_reply":"2022-05-16T04:15:51.468878Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-16T04:17:28.334343Z","iopub.execute_input":"2022-05-16T04:17:28.334870Z","iopub.status.idle":"2022-05-16T04:17:28.703314Z","shell.execute_reply.started":"2022-05-16T04:17:28.334831Z","shell.execute_reply":"2022-05-16T04:17:28.701954Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}